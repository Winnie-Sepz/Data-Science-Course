{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IOD_Demo-8_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5Py-h5uKz_h"
      },
      "source": [
        "<div>\n",
        "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tNoh0nfKz_l"
      },
      "source": [
        "# Demo 8.3: Web Scraping\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "- Run the cells\n",
        "- Observe and understand the results\n",
        "- Answer the questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMdVz2YLKz_p"
      },
      "source": [
        "# Web Scraping in Python (using BeautifulSoup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczGo5RcKz_s"
      },
      "source": [
        "# Basics HTML\n",
        "Before starting with the code, let’s understand the basics of HTML and some rules of scraping.\n",
        "\n",
        "## HTML tags\n",
        "Below is the source code for a simple HTML webpage.\n",
        "\n",
        "    <!DOCTYPE html>  \n",
        "    <html>  \n",
        "        <head>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1> First Scraping </h1>\n",
        "            <p> Hello World </p>\n",
        "        <body>\n",
        "    </html>\n",
        "    \n",
        "This is the basic syntax of an HTML webpage. Every `<tag>` serves a block inside the webpage:\n",
        "1. `<!DOCTYPE html>` HTML documents must start with a type declaration.\n",
        "2. The HTML document is contained between `<html>` and `</html>`.\n",
        "3. The meta and script declaration of the HTML document is between `<head>` and `</head>`.\n",
        "4. The visible part of the HTML document is between `<body>` and `</body>` tags.\n",
        "5. Title headings are defined with the `<h1>` through `<h6>` tags.\n",
        "6. Paragraphs are defined with the `<p>` tag.\n",
        "\n",
        "Other useful tags include `<a>` for hyperlinks, `<table>` for tables, `<tr>` for table rows, and `<td>` for table columns.\n",
        "\n",
        "Also, HTML tags sometimes come with `id` or `class` attributes. The `id` attribute specifies a unique id for an HTML tag and the value must be unique within the HTML document. The `class` attribute is used to define equal styles for HTML tags with the same class. We can make use of these ids and classes to help us locate the data we want.\n",
        "\n",
        "## Scraping Rules\n",
        "1. **Always** check a website’s **Terms and Conditions** before you scrape it. Be careful to read the statements about legal use of data. Usually, the retrieved data should not be used for commercial purposes.\n",
        "2. **Do not** request data from the website too aggressively with a program (also known as spamming), as this may break the website. Make sure the program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
        "3. The layout of a website may change from time to time, so make sure to revisit the site and rewrite the code as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfxsS1dnKz_v"
      },
      "source": [
        "## Inspecting the Page\n",
        "Let’s take one page from the **Memory Alpha** website as an example.\n",
        "\n",
        "To investigate some relationships let's get the links from this page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7yt4vvvKz_y"
      },
      "source": [
        "Open the web page on [Prinadora](http://memory-alpha.wikia.com/wiki/Prinadora) with the browser and inspect it.\n",
        "\n",
        "Hover the cursor on the text and follow the shaded box surrounding the main text.\n",
        "\n",
        "From the result, check the main text inside a few levels of HTML tags, which is `<section id=\"WikiaPage\" ...>` → `<div class=\"WikiaPageContentWrapper\">` → `<article id=\"WikiaMainContent\" class=\"WikiaMainContent\">`.\n",
        "\n",
        "The unique location of the data is now known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHnB_5JLKz_5"
      },
      "source": [
        "## Import Libraries\n",
        "import regex as re\n",
        "\n",
        "from urllib.parse import unquote\n",
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLPwo1PTK0AB"
      },
      "source": [
        "### Define the content to retrieve (webpage's URL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiR0AEi0K0AC"
      },
      "source": [
        "# specify the url\n",
        "quote_page = 'http://memory-alpha.wikia.com/wiki/Prinadora'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Pdi7U6K0AF"
      },
      "source": [
        "### Retrieve the page\n",
        "- Require Internet connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO1S9OLOK0AG",
        "outputId": "3941312b-8665-46ac-e0d6-9968140f40ee"
      },
      "source": [
        "# query the website and return the html to the variable ‘page’\n",
        "http = urllib3.PoolManager()\n",
        "r = http.request('GET', quote_page)\n",
        "if r.status == 200:\n",
        "    page = r.data\n",
        "    print('Type of the variable \\'page\\':', page.__class__.__name__)\n",
        "    print('Page Retrieved. Request Status: %d, Page Size: %d' % (r.status, len(page)))\n",
        "else:\n",
        "    print('Some problem occurred. Request Status: %s' % r.status)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of the variable 'page': bytes\n",
            "Page Retrieved. Request Status: 200, Page Size: 235389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaVlRuBAK0AI"
      },
      "source": [
        "### Convert the stream of bytes into a BeautifulSoup representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxwddKYZK0AJ",
        "outputId": "11487445-1fd5-460a-cc82-8dfb8788a979"
      },
      "source": [
        "# parse the html using beautiful soup and store in variable `soup`\n",
        "soup = BeautifulSoup(page, 'html.parser')\n",
        "print('Type of the variable \\'soup\\':', soup.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of the variable 'soup': BeautifulSoup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVw8D21eK0AM"
      },
      "source": [
        "### Check the content\n",
        "- The HTML source\n",
        "- Includes all tags and scripts\n",
        "- Can be long!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5oIwB2tK0AM"
      },
      "source": [
        "print(soup.prettify()[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJdaDTvYK0AP"
      },
      "source": [
        "### Check the HTML's Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC0D540CK0AQ",
        "scrolled": false
      },
      "source": [
        "print('Title tag :%s:' % soup.title)\n",
        "print('Title text:%s:' % soup.title.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaFq7vsOK0AY"
      },
      "source": [
        "### Wikimedia's article\n",
        "- Wiki pages use the tag `article` for the actual content of the page\n",
        "\n",
        "        <article class=\"WikiaMainContent\" id=\"WikiaMainContent\">\n",
        "            <div class=\"WikiaMainContentContainer\" id=\"WikiaMainContentContainer\">\n",
        "                <div class=\"WikiaArticle\" id=\"WikiaArticle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-HJ_xyiK0AY"
      },
      "source": [
        "tag = 'article'\n",
        "article = soup.find_all(tag)[0]\n",
        "print('Type of the variable \\'article\\':', article.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cw389dK0Aa"
      },
      "source": [
        "### Get some of the text\n",
        "- Plain text without HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptx4JvLaK0Ab",
        "scrolled": true
      },
      "source": [
        "# show the first 500 characters after removing redundant newlines\n",
        "print(re.sub(r'\\n\\n+', '\\n', article.text)[:500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCV5HRw3K0Ad"
      },
      "source": [
        "### Find the links in the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJNCkV4oK0Ad"
      },
      "source": [
        "# identify the type of tag to retrieve\n",
        "tag = 'a'\n",
        "# create a list with the links from the `<a>` tag\n",
        "tag_list = [t.get('href') for t in article.find_all(tag)]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zIsCxQMK0Ag"
      },
      "source": [
        "# keep only the links to the wiki itself\n",
        "tag_list = [t[6:] for t in tag_list if (t) and (t.startswith('/wiki/'))]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO5dSet3K0Ai"
      },
      "source": [
        "# create a filter for undesired links\n",
        "filter  = '(%s)' % '|'.join([\n",
        "    'Category:',\n",
        "    'File:',\n",
        "    'Help:',\n",
        "    'Memory_Alpha:',\n",
        "    'Portal:',\n",
        "    'action=',\n",
        "    'Special:',\n",
        "    'Star_Trek:',\n",
        "    'Star_Trek_',\n",
        "    'Talk:'\n",
        "])\n",
        "# remove the links that are found in the filter\n",
        "tag_list = [t for t in tag_list if not re.search(filter, t)]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0NWnoPK0Ak"
      },
      "source": [
        "# remove duplicates\n",
        "tag_list = list(set(tag_list))\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-92iBZK0Am"
      },
      "source": [
        "# convert escaped sequences\n",
        "tag_list = [unquote(t) for t in tag_list]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODJEoku8K0An"
      },
      "source": [
        "# convert underscore to space\n",
        "tag_list = [re.sub('_', ' ', t) for t in tag_list]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc77nPaDK0Ao",
        "scrolled": false
      },
      "source": [
        "# order the list\n",
        "tag_list.sort()\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh4ag5cSK0Ar"
      },
      "source": [
        "### Create a filter for unwanted types of articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdXMj4CSK0Ar"
      },
      "source": [
        "filter  = '(%s)' % '|'.join([\n",
        "    'episode',\n",
        "    'lternate_reality', # both Alternate_reality and alternate_reality\n",
        "    'mirror',\n",
        "    'rank',\n",
        "    'production',\n",
        "    'Season'\n",
        "])\n",
        "# remove the links that are found in the filter\n",
        "tag_list = [t for t in tag_list if not re.search(filter, t)]\n",
        "tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RERADKgNFq9T"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> > > > > > > > > © 2021 Institute of Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}