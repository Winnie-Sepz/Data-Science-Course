{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g36zl082ngTW"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lADS54PMngTd"
   },
   "source": [
    "# Lab 10.2 - Deployment via Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy8P7DUVngTd"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV07z-kbngTe"
   },
   "source": [
    "**Note**: This notebook should work on your local machine. There is no need to use AWS SageMaker for this lab.\n",
    "\n",
    "The purpose of this lab is to take you through the process of deploying a machine learning web app on a publicly hosted platform (Heroku). A trained model will be created using the Scikit-learn pipeline (combining loading, preprocessing and training steps), then separate files of Python code and text will need to be completed to complete the components necessary for deployment. Firstly the app will be deployed to your local machine (so that you can view it in your browser). Once that it is sucessful the files will be uploaded to a new repository you create in GitHub and then Heroku will read from this to host the application via a publicly accessible URL. \n",
    "\n",
    "The app will take in a text string from a user and output a prediction of whether that string is expressing positive or negative sentiment. The model is created using methods from Module 8 (Natural Language Processing). Since the training data used to create the model is small (300 records), the prediction may only be accurate around 70% of the time. In future you may wish to improve this app's performance or develop your own app in a similar manner.\n",
    "\n",
    "The following files are needed to create the app:\n",
    "\n",
    "- requirements.txt\n",
    "- app.py\n",
    "- Procfile\n",
    "- model.joblib\n",
    "- utils.py\n",
    "\n",
    "\n",
    "Firstly we will see how a predictive model can be created as a pipe which combines the preprocessing, feature engineering and model training steps. This model is then saved as a joblib pickle file which can be reloaded at any time to avoid retraining.\n",
    "\n",
    "This trained model can be loaded within your production environment along with required packages and real-time predictions can be made by calling its predict() method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUDy4T6lngTe"
   },
   "source": [
    "Flask is a web app framework written in Python. It enables one to run application code whose output can be viewed on a browser. It is installed as a Python library via `pip install flask`. For a sample \"Hello World\" application see https://palletsprojects.com/p/flask/.\n",
    "\n",
    "Note that Flask does not scale up for use in large deployment applications (ones involving many frequent API requests)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGPke9L-ngTf"
   },
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "89YezCYAngTf"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/anaconda3/lib/python3.8/site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/anaconda3/lib/python3.8/site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/anaconda3/lib/python3.8/site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /opt/anaconda3/lib/python3.8/site-packages (3.0.6)\n",
      "Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.4 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ewWwVQ6ngTf"
   },
   "source": [
    "The training data set is `sentiments.csv`, a dataset used in the NLP module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b2aqcXsJngTg"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('/Users/winifredwetthasinghe/Documents/Data_Science_Course_UTS/Labs/DATA/sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XTCOPZRhngTg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AZcwxmTWngTg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment source\n",
       "0                           Wow... Loved this place.          1   yelp\n",
       "1                                 Crust is not good.          0   yelp\n",
       "2          Not tasty and the texture was just nasty.          0   yelp\n",
       "3  Stopped by during the late May bank holiday of...          1   yelp\n",
       "4  The selection on the menu was great and so wer...          1   yelp"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGUOIOoVngTg"
   },
   "source": [
    "Next we define a function to do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nJzWOdJFngTh"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hzeU0m26ngTh"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAAkXf8QngTh"
   },
   "source": [
    "The following NLP model is used for further preprocessing. The following steps are the same as used in Module 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5fLryrkqngTh"
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7T6JkusEngTi"
   },
   "outputs": [],
   "source": [
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cv68vbxvngTi"
   },
   "outputs": [],
   "source": [
    "df['short'] = df['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TO0pVbccngTi"
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['short']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LCQJTMsLngTi"
   },
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m_Jf4Uz7ngTj"
   },
   "outputs": [],
   "source": [
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JQBz2QWtngTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "# create a matrix of word counts from the text\n",
    "# use TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "# do the actual counting\n",
    "A = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)\n",
    "\n",
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = tfidf.transform(X_test)\n",
    "\n",
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)\n",
    "\n",
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-xDtW7engTj"
   },
   "source": [
    "We will not attempt to improve on the performance in this lab as we are more interested in how to deploy the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6dAZG6NngTj"
   },
   "source": [
    "Next we create a pipeline to simplify the process of model creation. We first define a preprocessor class which applies the `clean_text` and `convert_text` functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6Ev0pVCZngTj"
   },
   "outputs": [],
   "source": [
    "class preprocessor(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "         return X.apply(clean_text).apply(convert_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2YRGr-SngTk"
   },
   "source": [
    "Next we combine the preprocessing, feature engineering and modelling steps into a single pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CP1SO4VvngTk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor', preprocessor()),\n",
       "                ('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('linearsvc', LinearSVC())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessor(), tfidf, classifier)\n",
    "pipe.fit(df['text'],df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhMEk0WwngTk"
   },
   "source": [
    "**Exercise**: test the resulting model on phrases of positive and negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iiJQb2OungTk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series('Positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "COadky0OngTk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series('Bad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1waSUGC5ngTl"
   },
   "source": [
    "The model can be saved in joblib file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rSPAXkxIngTl"
   },
   "outputs": [],
   "source": [
    "joblib.dump(pipe, open('model.joblib','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMyPuWCgngTl"
   },
   "source": [
    "Reload the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CfLnlSS3ngTl"
   },
   "outputs": [],
   "source": [
    "newpipe = joblib.load(open('model.joblib','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-BVikfgDngTl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newpipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRVJm67SngTl"
   },
   "source": [
    "Testing this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eduEUSe0ngTm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(newpipe.predict(pd.Series('awesome place'))[0])\n",
    "print(newpipe.predict(pd.Series('terrible!'))[0])\n",
    "print(newpipe.predict(pd.Series('very interesting'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQ19E6fAngTm"
   },
   "source": [
    "Once satisified that we have a model ready for deployment, we can write a self-contained script that loads the model and can make predictions on the fly. This is partially done for you in the file \"app.py\". Then this script can be run without requiring the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIsIZi1nngTm"
   },
   "source": [
    "**Exercise**: Refer to app.py and fill in the missing code based on the code above using a text editor such as Spyder. Observe how it links to utils.py which contains the preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WLnh2G_ngTm"
   },
   "source": [
    "### Local hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki3u6XcongTn"
   },
   "source": [
    "**Exercise**: Open the index.html with the text editor and fill in the missing HTML code there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5wbhhUMngTn"
   },
   "source": [
    "Using Anaconda prompt (Windows) or a Terminal window (Mac) run \"python app.py\". This deploys the app locally on http://127.0.0.1:5000/ (or similar) which you can then view on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlXMFAKHngTn"
   },
   "source": [
    "Feel free to be creative and redesign the webpage by modifying the .css and .html pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8EMRPMMngTn"
   },
   "source": [
    "**Bonus Exercise**: Redesign the webpage by modifying the .css and .html pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAPu4L42ngTn"
   },
   "source": [
    "### Deployment via Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlgbv9U-ngTn"
   },
   "source": [
    "So far you have deployed your model on your local machine. Now we seek to deploy it publicly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvFxF3URngTo"
   },
   "source": [
    "There are two additional files needed for external deployment of your model: \n",
    "- requirements.txt includes the versions of packages that are to be used with the app. \n",
    "- Procfile specifies the processes to be run on the Heroku dyno (see https://blog.heroku.com/the_new_heroku_1_process_model_procfile). Dynos are virtualised Linux containers used to run web apps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ny26df2RngTo"
   },
   "source": [
    "In the Procfile you will see mention of `gunicorn`. Gunicorn (Green Unicorn) manages the Flask application. It is a Python HTTP server for applications over a Web Service Gateway Interface (WSGI). It allows one to run a Python application concurrently by running multiple processes on a single machine. Further information is at https://docs.gunicorn.org/en/stable/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkiY53j_ngTo"
   },
   "source": [
    "To update the `requirements.txt` file use the `__version__` attribute to see the version of packages being used. This ensures that your model is reproducible on other computing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "c5x6cK0hngTo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CMiw_GMNngTo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_core_web_sm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9aFj1tSngTp"
   },
   "source": [
    "Log into your GitHub account and create a new repository containing the following files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWsbeZROngTp"
   },
   "source": [
    "- requirements.txt\n",
    "- app.py\n",
    "- Procfile\n",
    "- model.joblib\n",
    "- utils.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65w6LdT8ngTp"
   },
   "source": [
    "Next sign up for a free account at http://signup.heroku.com (a Platform As A Service). You will receive an email link to activate the account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjnSLfxkngTp"
   },
   "source": [
    "Once signed into heroku.com click on \"Create new app\". Choose a unique app name and leave the region as USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_-aaR13ngTp"
   },
   "source": [
    "Next connect via GitHub to the repository you recently created. Then select Manual deploy -> Deploy Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxGlPm-YngTp"
   },
   "source": [
    "Eventually it will say `https://<your app name>.herokuapp.com/ deployed to Heroku`. Navigate your browser to this location to see if your deployment was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKrFeFJ7ngTp"
   },
   "source": [
    "If deployment was unsuccessful it may be necessary to download Heroku's command line interface to view error messages. This is available at https://devcenter.heroku.com/articles/heroku-cli#download-and-install. Type `heroku login` at the command prompt or terminal window to start the command line interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXqLdKu2ngTq"
   },
   "source": [
    "If you managed to see your app successfully, congratulations! You now know how to deploy an app on the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRU9vstwngTq"
   },
   "source": [
    "Note that if working in part of a larger software system it is good practice to have versioning of code (e.g. with GitHub) and also make use of CI/CD software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdD9tModngTq"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H47sXcSrngTq"
   },
   "source": [
    "More information on pipelines:\n",
    "- https://gist.github.com/amberjrivera/8c5c145516f5a2e894681e16a8095b5c\n",
    "- https://scikit-learn.org/stable/modules/compose.html#pipeline\n",
    "\n",
    "More on Flask for web app deployment:\n",
    "- https://flask.palletsprojects.com/en/1.1.x/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg27j7zkngTq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "IOD_Lab-10_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
